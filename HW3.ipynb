{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ - определение ССЗ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таргет - наличие сердечно-сосудистых заболеваний (ССЗ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,  mean_squared_error, log_loss\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "#from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_case2.csv', ';')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наши данные на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1), \n",
    "                                                    df['cardio'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К полям:\n",
    "- gender, cholesterol применим OHE-кодирование\n",
    "- age, height, weight, ap_hi, ap_lo - standardScaler\n",
    "- gluc, smoke, alco, active - оставим пока как есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь объединим все наши трансформеры с помощью FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим классификатор и запустим кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clfr = None):\n",
    "    if clfr == None:\n",
    "        clfr = LogisticRegression(random_state = 42) \n",
    "\n",
    "    classifier = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('classifier', clfr),\n",
    "    ])\n",
    "\n",
    "    #запустим кросс-валидацию\n",
    "    print(\"Кросс-валидация ...\")\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "    cv_score_mean = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "\n",
    "    print(\"Обучение на всем тренировочном наборе ...\")\n",
    "    #обучим пайплайн на всем тренировочном датасете\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(\"Предсказание ...\")\n",
    "    y_score = classifier.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    r={\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_score_mean': cv_score_mean,\n",
    "        'cv_score_std': cv_score_std,\n",
    "        'y_score': y_score\n",
    "    }\n",
    "\n",
    "    return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(r, metric_name, threshold):\n",
    "    \n",
    "    if 'metrics' not in r:\n",
    "        r['metrics'] = {}\n",
    "    r[metric_name] = {}\n",
    "    d = r['metrics'][metric_name] = {}\n",
    "    d['best_threshold'] = threshold\n",
    "    y_score = r['y_score']\n",
    "    d['roc_auc_score'] = roc_auc_score(y_true=y_test, y_score=y_score)\n",
    "    d['log_loss_score'] = log_loss(y_true=y_test, y_pred=y_score)\n",
    "    \n",
    "    d['confusion_matrix'] = cnf_matrix = confusion_matrix(y_test, y_score > threshold)\n",
    "\n",
    "    TN = cnf_matrix[0][0]\n",
    "    FN = cnf_matrix[1][0]\n",
    "    TP = cnf_matrix[1][1]\n",
    "    FP = cnf_matrix[0][1]\n",
    "\n",
    "    d['TPR']= TP/(TP+FN)\n",
    "    d['FPR'] = FP/(FP+TN)\n",
    "    d['TNR'] = TN/(FP+TN)\n",
    "\n",
    "    d['precision'] = precision = TP / (TP + FP)\n",
    "    d['recall'] = recall = TP / (TP + FN)\n",
    "\n",
    "    b=1\n",
    "    fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "    d['fscore'] = fscore\n",
    "    \n",
    "    return r\n",
    "\n",
    "def get_metrics_fscore(r):\n",
    "    y_score = r['y_score']\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "    b=1\n",
    "    fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "    return get_metrics(r, 'fscore', thresholds[np.argmax(fscore)])\n",
    "\n",
    "def get_metrics_business(r, rubl_to_test = 3000, rubl_to_early_treatment = 20000, rubl_to_late_treatment = 30000):\n",
    "    costs = []\n",
    "    metric = []\n",
    "    thresholds = np.linspace(0, 1, 20).tolist()\n",
    "    y_score = r['y_score']\n",
    "\n",
    "    for t in thresholds:\n",
    "        cnf_matrix = confusion_matrix(y_test, y_score > t)\n",
    "        rubl_no_tests = (cnf_matrix[1][1]+cnf_matrix[1][0]) * rubl_to_late_treatment\n",
    "        rubl_all_test = np.sum(cnf_matrix) * rubl_to_test + (cnf_matrix[1][0]+cnf_matrix[1][1]) * rubl_to_early_treatment\n",
    "        rubl_ML = (cnf_matrix[1][1]+cnf_matrix[0][1]) * rubl_to_test + cnf_matrix[1][0] * rubl_to_late_treatment + cnf_matrix[1][1] * rubl_to_early_treatment\n",
    "        metric.append(rubl_all_test - rubl_ML)\n",
    "        costs.append((rubl_no_tests, rubl_all_test, rubl_ML))\n",
    "\n",
    "    print(metric)\n",
    "        \n",
    "    ix = np.argmax(metric)\n",
    "    r = get_metrics(r, 'business', thresholds[ix])\n",
    "    r['metrics']['business']['notes']= [f\"Выгода: {metric[ix]}; Расходы: без тестирования: {costs[ix][0]}, с полным тестированием: {costs[ix][1]}, с ML: {costs[ix][2]}\"]\n",
    "    return r\n",
    "\n",
    "def print_metrics(r):\n",
    "    print(f\"Cross-validation score: {r['cv_score_mean']:.3f}+-{r['cv_score_std']:.3f}\")\n",
    "    for mn in r['metrics']:\n",
    "        d = r['metrics'][mn]\n",
    "        print(f\"Metrics (optimal threshold for {mn} = {d['best_threshold']:.3f}): \")\n",
    "        print(f\"    fscore: {d['fscore']:.3f}, precision: {d['precision']:.3f}, recall: {d['recall']:.3f}, ROC AUC: {d['roc_auc_score']:.3f}, Log loss: {d['log_loss_score']:.3f}\")\n",
    "        print(f\"    TPR: {d['TPR']:.3f}, FPR: {d['FPR']:.3f}, TNR: {d['TNR']:.3f}\")\n",
    "        if 'notes' in d:\n",
    "            for n in d['notes']:\n",
    "                print(f\"    {n}\")\n",
    "        print(f\"    Confusion matrix: \")\n",
    "        print(f\"        \", d['confusion_matrix'][0])\n",
    "        print(f\"        \", d['confusion_matrix'][1])\n",
    "    return r\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc_auc(r):\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_color_codes(\"muted\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    fpr, tpr, thresholds_ = roc_curve(y_test, r['y_score'], pos_label=1)\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve ')\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.savefig(\"ROC.png\")\n",
    "    plt.show()\n",
    "    return r\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кросс-валидация ...\n",
      "Обучение на всем тренировочном наборе ...\n",
      "Предсказание ...\n",
      "Кросс-валидация ...\n",
      "Обучение на всем тренировочном наборе ...\n",
      "Предсказание ...\n",
      "Кросс-валидация ...\n",
      "Обучение на всем тренировочном наборе ...\n",
      "Предсказание ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import catboost as catb\n",
    "\n",
    "results = {}\n",
    "results['LogisticRegression'] = fit_predict(LogisticRegression(random_state = 42))\n",
    "results['RandomForest'] = fit_predict(RandomForestClassifier(random_state = 42))\n",
    "results['CatBoost'] = fit_predict(catb.CatBoostClassifier(silent=True, random_state = 42))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------LogisticRegression-------------------------\n",
      "[0, -125000, 251000, 1282000, 2665000, 3991000, 4812000, 4810000, 3638000, 1848000, -1413000, -4830000, -8737000, -13212000, -17790000, -22453000, -26845000, -30612000, -33325000, -34300000]\n",
      "Cross-validation score: 0.786+-0.004\n",
      "Metrics (optimal threshold for fscore = 0.387): \n",
      "    fscore: 0.730, precision: 0.647, recall: 0.837, ROC AUC: 0.784, Log loss: 0.578\n",
      "    TPR: 0.837, FPR: 0.449, TNR: 0.551\n",
      "    Confusion matrix: \n",
      "         [4861 3959]\n",
      "         [1411 7269]\n",
      "Metrics (optimal threshold for business = 0.316): \n",
      "    fscore: 0.719, precision: 0.594, recall: 0.911, ROC AUC: 0.784, Log loss: 0.578\n",
      "    TPR: 0.911, FPR: 0.613, TNR: 0.387\n",
      "    Выгода: 4812000; Расходы: без тестирования: 260400000, с полным тестированием: 226100000, с ML: 221288000\n",
      "    Confusion matrix: \n",
      "         [3410 5410]\n",
      "         [ 774 7906]\n",
      "-------------------------RandomForest-------------------------\n",
      "[119000, 1200000, 2445000, 3344000, 3924000, 3943000, 3659000, 3148000, 2332000, 1491000, 232000, -1286000, -3778000, -6177000, -9240000, -13079000, -19364000, -25558000, -31528000, -34300000]\n",
      "Cross-validation score: 0.775+-0.001\n",
      "Metrics (optimal threshold for fscore = 0.350): \n",
      "    fscore: 0.719, precision: 0.647, recall: 0.808, ROC AUC: 0.771, Log loss: 0.599\n",
      "    TPR: 0.808, FPR: 0.434, TNR: 0.566\n",
      "    Confusion matrix: \n",
      "         [4991 3829]\n",
      "         [1663 7017]\n",
      "Metrics (optimal threshold for business = 0.263): \n",
      "    fscore: 0.715, precision: 0.605, recall: 0.875, ROC AUC: 0.771, Log loss: 0.599\n",
      "    TPR: 0.875, FPR: 0.563, TNR: 0.437\n",
      "    Выгода: 3943000; Расходы: без тестирования: 260400000, с полным тестированием: 226100000, с ML: 222157000\n",
      "    Confusion matrix: \n",
      "         [3853 4967]\n",
      "         [1088 7592]\n",
      "-------------------------CatBoost-------------------------\n",
      "[0, 559000, 1968000, 3671000, 4777000, 5580000, 5631000, 4969000, 3855000, 2552000, 953000, -1285000, -3080000, -4784000, -6701000, -10246000, -19669000, -30473000, -33878000, -34300000]\n",
      "Cross-validation score: 0.801+-0.002\n",
      "Metrics (optimal threshold for fscore = 0.386): \n",
      "    fscore: 0.739, precision: 0.691, recall: 0.795, ROC AUC: 0.801, Log loss: 0.542\n",
      "    TPR: 0.795, FPR: 0.349, TNR: 0.651\n",
      "    Confusion matrix: \n",
      "         [5738 3082]\n",
      "         [1780 6900]\n",
      "Metrics (optimal threshold for business = 0.316): \n",
      "    fscore: 0.737, precision: 0.642, recall: 0.863, ROC AUC: 0.801, Log loss: 0.542\n",
      "    TPR: 0.863, FPR: 0.473, TNR: 0.527\n",
      "    Выгода: 5631000; Расходы: без тестирования: 260400000, с полным тестированием: 226100000, с ML: 220469000\n",
      "    Confusion matrix: \n",
      "         [4649 4171]\n",
      "         [1188 7492]\n"
     ]
    }
   ],
   "source": [
    "for classifier_name in results:\n",
    "    print('-------------------------' + classifier_name + '-------------------------')\n",
    "    print_metrics(get_metrics_business(get_metrics_fscore(results[classifier_name])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отчет и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "\n",
    "Использовались LogisticRegression, RandomForestClassifier, CatBoostClassifier с фиксированным random_state и параметрами по умолчанию.\n",
    "\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "\n",
    "Использовалась \n",
    "\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "\n",
    "Выведены все метрики, в том числе бизнес-метрика \"выгода от предсказания ССЗ с помощью МО по сравнению с полным тестированием\". Как ожидалась, оптимизация под бизнес-метрику давала разумный результат и выгоду при сравнительно высокой цене тестов. При низкой цене тестов выгоднее было протестировать всех.\n",
    "\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "\n",
    "Лучше всего справилась модель CatBoostClassifier, по fscore, ROC-AUC и бизнес-метрике. Интересно, что простая модель LogicsticRegression оказалась на втором месте. Но сравнение не очень объективное, так как настройка параметров не производилась, использовались параметры по умолчанию. \n",
    "\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
